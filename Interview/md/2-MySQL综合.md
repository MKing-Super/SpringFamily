



# MySQL综合

## 四、MySQL

### 1、Select 语句完整的执行顺序

**1. `FROM` 和 `JOIN`（数据源与连接）**

- •**作用**：加载主表及关联表，生成笛卡尔积（所有可能的行组合）。
- •**MySQL 优化**：优化器可能优先选择小表作为驱动表（减少中间结果集）。

**2. `ON`（连接条件过滤）**

- •**作用**：根据 `JOIN` 条件筛选有效行（如 `ON orders.user_id = users.id`）。
- •**注意**：仅影响关联表，主表数据保留（外连接时）。

**3. `OUTER JOIN` 补 `NULL`（外连接处理）**

- •**作用**：若使用 `LEFT/RIGHT JOIN`，为主表未匹配的行填充 `NULL`。

```sql
FROM users
LEFT JOIN orders ON users.id = orders.user_id
```

→ 即使无订单的用户也会保留（`orders` 字段为 `NULL`）。

**4. `WHERE`（行级过滤）**

- •**作用**：过滤不符合条件的行（**不能使用聚合函数或 SELECT 别名**）。
- •**MySQL 优化**：

- •优先使用索引加速过滤（如 `WHERE id = 100` 走主键索引）。
- •无法使用索引时触发全表扫描（性能低下）。

**5. `GROUP BY`（分组）**

- •**作用**：按指定列分组（如 `GROUP BY department`），每组生成一行。
- •**MySQL 特性**：

- •允许 `SELECT` 非聚合列（如 `SELECT name, SUM(salary)`），但结果不确定（其他数据库会报错）。
- •使用 `ONLY_FULL_GROUP_BY` 模式可禁止此行为。

**6. `HAVING`（组级过滤）**

- •**作用**：过滤分组后的结果（**可使用聚合函数**，如 `HAVING SUM(sales) > 1000`）。
- •**与 WHERE 区别**：
  `WHERE` 在分组前过滤单行，`HAVING` 在分组后过滤整个组。

**7. 窗口函数（Window Functions）**

- •**作用**：计算分组内聚合值（如 `ROW_NUMBER()`, `SUM() OVER()`）。
- •**执行时机**：在 `GROUP BY` 之后、`SELECT` 之前。

```sql
SELECT name, salary, 
       RANK() OVER(PARTITION BY dept ORDER BY salary DESC) AS rank
```

**8. `SELECT`（选择列）**

- •**作用**：确定返回的列（可包含表达式、聚合函数）。
- •**关键限制**：

- •此时才可定义别名（如 `SELECT SUM(amount) AS total`）。
- •别名在后续步骤（`ORDER BY`, `HAVING`）中可用，但在 `WHERE` 中不可用。

**9. `DISTINCT`（去重）**

- •**作用**：删除重复行（如 `SELECT DISTINCT city`）。
- •**性能警告**：

- •对大数据集可能触发临时表或文件排序（`Using temporary; Using filesort`）。

**10. `ORDER BY`（排序）**

- •**作用**：按指定列排序（如 `ORDER BY total_sales DESC`）。
- •**MySQL 特性**：

- •可引用 `SELECT` 别名（如 `ORDER BY total`）。
- •无索引时触发全结果集排序（`Using filesort`），大数据集性能差。

**11. `LIMIT` / `OFFSET`（分页）**

- •**作用**：限制返回行数（如 `LIMIT 10 OFFSET 20`）。
- •**MySQL 优化**：

- •`LIMIT` 可提前终止查询（如找到 10 行后停止扫描）。
- •大偏移量（`OFFSET 100000`）性能差（需扫描跳过行）。

示例：

```sql
SELECT                          -- 8. 选择列
    country,                   
    COUNT(*) AS order_count     -- 别名 order_count
FROM orders                     -- 1. 主表
JOIN users ON orders.user_id = users.id  -- 2. 连接条件
WHERE status = 'shipped'        -- 4. 行级过滤
GROUP BY country               -- 5. 分组
HAVING order_count > 50        -- 6. 组级过滤（用别名）
ORDER BY order_count DESC      -- 10. 排序（用别名）
LIMIT 10;                      -- 11. 分页
```

1.1**MySQL 优化器的影响**

虽然逻辑顺序固定，但 MySQL 优化器可能调整物理执行顺序以提高性能：

1. 1.**谓词下推**：将 `WHERE` 条件提前到 `JOIN` 前执行（减少中间数据）。
2. 2.**索引优化**：优先使用索引满足 `WHERE`、`ORDER BY`、`GROUP BY`。
3. 3.**子查询优化**：可能将子查询转化为 `JOIN` 操作。

可通过 `EXPLAIN` 命令查看实际执行计划

1.2 **谓词下推 (Predicate Pushdown)**

**是什么？**
		 “谓词”指的是查询中的过滤条件（如 `WHERE column = value`）。“下推”指的是优化器尽可能早地将这些过滤条件应用到查询计划中，**在生成中间结果集之前就进行过滤**，从而最大限度地减少需要处理的数据量。

**为什么重要？**
		在连接（JOIN）操作中，处理的数据行数越少，性能越好。谓词下推的核心思想就是“尽早过滤”。

```sql
-- 优化前
SELECT *
FROM orders o
JOIN customers c ON o.customer_id = c.id
WHERE c.country = 'USA';

-- 优化后
SELECT *
FROM orders o
JOIN (
    SELECT * FROM customers 
    WHERE country = 'USA'  -- 谓词下推到这里
) c ON o.customer_id = c.id;
```

1.3 **索引优化 (Index Optimization)**

**是什么？**
 		优化器会根据查询条件、排序要求、分组操作等，尝试选择最高效的索引来加速查询，避免全表扫描。

**为什么重要？**
		使用索引就像使用书的目录，可以快速定位数据，而全表扫描则像一页一页地翻书，效率天差地别。

1.4 **子查询优化 (Subquery Optimization)**

**是什么？**
 		MySQL 优化器会尝试将效率低下的**相关子查询** 或 **IN 子查询** 改写为效率更高的 **JOIN** 或 **半连接 (Semi-join)** 操作。

**为什么重要？**
 		传统的子查询（尤其是相关子查询）通常需要对外部查询的每一行都执行一次内部查询，性能极差（O(n²) 复杂度）。将其转化为表连接可以大幅提升性能。

```sql
-- 优化前
SELECT * FROM products p
WHERE p.id IN (
    SELECT product_id FROM orders
    WHERE order_date > '2023-01-01'
);

-- 优化后
SELECT p.* 
FROM products p
SEMI JOIN orders o ON p.id = o.product_id   -- MySQL 内部转换
WHERE o.order_date > '2023-01-01';
```

1.5 **优化器总结**

| 优化策略       | 核心思想                                                     | 对性能的影响                                         |
| :------------- | :----------------------------------------------------------- | :--------------------------------------------------- |
| **谓词下推**   | **尽早过滤**，减少后续操作（如 JOIN）的数据量。              | 极大减少 I/O 和计算量，尤其对大表关联至关重要。      |
| **索引优化**   | **快速访问**，利用“数据目录”避免全表扫描。                   | 是查询性能的基石，覆盖索引和索引下推效果显著。       |
| **子查询优化** | **去嵌套化**，将低效的嵌套循环转换为高效的集合操作（如 JOIN）。 | 将 O(n²) 复杂度的操作变为 O(n)，性能提升几个数量级。 |

**关键优化标志**：

1. 1.**谓词下推**：`EXPLAIN` 显示分区表提前过滤
2. 2.**索引下推**：`Using index condition`
3. 3.**子查询优化**：`Start temporary/End temporary` 或 `MATERIALIZED`

| 优化策略          | 优化前问题             | 优化后方案                   | 性能提升关键          |
| ----------------- | ---------------------- | ---------------------------- | --------------------- |
| **谓词下推**      | JOIN 大表全量数据      | 先过滤再 JOIN                | 减少 90%+ JOIN 数据量 |
| **索引下推(ICP)** | 存储引擎只过滤最左前缀 | 存储引擎直接过滤所有索引条件 | 减少 90%+ 回表操作    |
| **子查询优化**    | O(n²) 嵌套循环执行     | 转换为 O(n) 的半连接操作     | 避免逐行执行子查询    |



### 2、MySQL事务

事务的基本要素（ACID）

- 原子性（Atomicity）：事务开始后所有操作，要么全部做完，要么全部不做，不可能停滞在中间环节。事务执行过程中出错，会回滚到事务开始前的状态，所有的操作就像没有发生一样。也就是说事务是一个不可分割的整体，就像化学中学过的原子，是物质构成的基本单位
- 一致性（Consistency）：事务开始前和结束后，数据库的完整性约束没有被破坏 。比如A向B转账，不可能A扣了钱，B却没收到。
- 隔离性（Isolation）：同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。比如A正在从一张银行卡中取钱，在A取钱的过程结束前，B不能向这张卡转账。
- 持久性（Durability）：事务完成后，事务对数据库的所有更新将被保存到数据库，不能回滚。

事务的并发问题

**1. 脏读 (Dirty Read)**

- •**问题描述**：一个事务读到了另一个**未提交事务**修改的数据。
- •**产生原因**：事务 A 修改数据后尚未提交，事务 B 读取了这个“中间状态”的数据。然后事务 A 因某种原因**回滚**了，那么事务 B 读到的就是数据库中从未正式存在过的、无效的“脏数据”。

**2. 不可重复读 (Non-Repeatable Read)**

- •**问题描述**：一个事务内，**两次读取同一行**数据，结果不一致。
- •**产生原因**：在事务 A 两次读取的间隔中，另一个事务 B **更新并提交**了这行数据。

**3. 幻读 (Phantom Read)**

- •**问题描述**：一个事务内，**两次执行相同的查询**，返回的**结果集行数**不一致。
- •**产生原因**：在事务 A 两次查询的间隔中，另一个事务 B **插入或删除**了满足查询条件的行并提交。

**4. 丢失更新 (Lost Update)**

- •**问题描述**：两个事务都读取了同一数据并试图修改它，最后提交的修改覆盖了先提交的修改，导致先前的更新“丢失”。

并发问题解决方案：

**1. 事务隔离级别 (Isolation Levels)**

​		这是最直接的应用层解决方案。SQL标准定义了4个隔离级别，级别越高，一致性越强，但并发性能越低。

| 隔离级别                        | 脏读 | 不可重复读 | 幻读 | 丢失更新 | 原理简述                                     |
| :------------------------------ | :--: | :--------: | :--: | :------: | :------------------------------------------- |
| **读未提交** (Read Uncommitted) |  ❌   |     ❌      |  ❌   |    ❌     | 几乎不加锁，性能最好，但问题最多。           |
| **读已提交** (Read Committed)   |  ✅   |     ❌      |  ❌   |    ❌     | **MVCC核心**：只能读到已提交的数据。         |
| **可重复读** (Repeatable Read)  |  ✅   |     ✅      |  ❌   |   ✅(*)   | **MVCC+锁**：事务开始时创建数据快照。        |
| **串行化** (Serializable)       |  ✅   |     ✅      |  ✅   |    ✅     | **加锁核心**：强制事务串行执行，最高隔离性。 |

**2. 锁 (Locking)**

- •**悲观锁**：默认认为并发冲突会发生，故先加锁再访问。 •**共享锁 (S Lock / 读锁)**：允许其他事务读，但不允许写。`SELECT ... LOCK IN SHARE MODE;` •**排他锁 (X Lock / 写锁)**：不允许其他事务读和写。`SELECT ... FOR UPDATE;`
- •**乐观锁**：默认认为冲突很少发生，不加锁。在提交时检查数据版本号（如`version`字段或时间戳），如果版本号变化则拒绝提交，让应用层重试。适用于读多写少的场景。



| 并发问题       | 本质               | 解决方案                                                     |
| :------------- | :----------------- | :----------------------------------------------------------- |
| **脏读**       | 读到未提交的数据   | **读已提交**隔离级别或更高                                   |
| **不可重复读** | 同一行数据值被修改 | **可重复读**隔离级别或更高、**行锁**                         |
| **幻读**       | 结果集行数发生变化 | **串行化**隔离级别、**Next-Key Lock**                        |
| **丢失更新**   | 覆盖他人的修改     | **可重复读**+**悲观锁**(`SELECT ... FOR UPDATE`)、**乐观锁** |



### 3、MyISAM和InnoDB的区别

| **特性**                   | **MyISAM**                       | **InnoDB**                     |
| -------------------------- | -------------------------------- | ------------------------------ |
| **事务支持**               | ❌ 不支持                         | ✅ 支持 ACID 事务（提交/回滚）  |
| **锁机制**                 | 表级锁（写阻塞整个表）           | 行级锁（仅锁定受影响的行）     |
| **外键约束**               | ❌ 不支持                         | ✅ 支持外键（保证数据完整性）   |
| **崩溃恢复**               | 弱（需手动修复表）               | 强（通过 Redo Log 自动恢复）   |
| **索引结构**               | 非聚簇索引（数据与索引分离）     | 聚簇索引（数据按主键物理排序） |
| **全文索引**               | ✅ 支持（FULLTEXT）               | ✅ MySQL 5.6+ 支持全文索引      |
| **缓存机制**               | 仅缓存索引（数据依赖 OS 缓存）   | 缓存索引+数据（Buffer Pool）   |
| **适用场景**               | 读密集型（如数据仓库、日志分析） | 读写混合（如电商、金融系统）   |
| **默认引擎（MySQL 5.5+）** | ❌ 非默认                         | ✅ 默认引擎                     |

3.1 **全文索引**

​		**全文索引（Full-Text Index）** 是一种专门用于**高效检索文本内容**的数据库索引技术。它通过解析文本中的关键词（分词），建立倒排索引结构，实现对大规模文本数据的快速关键词搜索，解决了传统 `LIKE` 模糊查询的性能瓶颈。

示例：

```sql
-- 创建新闻表，包含标题和内容字段
CREATE TABLE news (
    id INT AUTO_INCREMENT PRIMARY KEY,
    title VARCHAR(200) NOT NULL,
    content TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FULLTEXT ft_index (title, content) WITH PARSER ngram -- 创建联合全文索引
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

-- 查看索引状态
SHOW INDEX FROM news;

-- 插入示例新闻数据
INSERT INTO news (title, content) VALUES
('人工智能改变医疗行业', '人工智能在医疗影像分析、药物研发等领域取得突破性进展，大幅提高诊断准确率。'),
('全球气候变化峰会召开', '各国领导人齐聚纽约，讨论减少碳排放和应对全球气候变化的紧急措施。'),
('5G技术推动物联网发展', '5G网络的高速低延迟特性为智能家居、自动驾驶等物联网应用提供强大支持。'),
('区块链在金融领域的应用', '多家银行采用区块链技术提升跨境支付效率和安全性，降低交易成本。'),
('量子计算机研究新突破', '科学家成功实现量子霸权，解决传统计算机无法处理的复杂问题。');

-- 搜索包含"人工智能"的文章
SELECT 
    id, 
    title,
    MATCH(title, content) AGAINST('人工智能') AS relevance_score
FROM news
WHERE MATCH(title, content) AGAINST('人工智能' IN NATURAL LANGUAGE MODE)
ORDER BY relevance_score DESC;

+----+--------------------------+---------------------+
| id | title                    | relevance_score     |
+----+--------------------------+---------------------+
|  1 | 人工智能改变医疗行业      | 0.0906190574169159 |
+----+--------------------------+---------------------+
```

3.2 **与传统 `LIKE` 查询的对比**

| **特性**       | **全文索引**               | **`LIKE '%keyword%'`**     |
| -------------- | -------------------------- | -------------------------- |
| **性能**       | 毫秒级响应（百万数据）     | 全表扫描（秒级甚至分钟级） |
| **匹配方式**   | 关键词搜索（支持自然语言） | 字符串模式匹配             |
| **多词搜索**   | ✅ 支持 “quick AND fox”     | ❌ 只能单词模糊匹配         |
| **排序相关性** | ✅ 结果按相关性排序         | ❌ 无序                     |
| **中文支持**   | 需配合分词器（如 ngram）   | 直接支持（但性能差）       |

3.3 **全文索引的局限性**

1. 1.**数据更新代价高**
   每次插入/修改文本需重建索引（影响写入性能）。
2. 2.**内存与磁盘消耗**
   倒排索引可能比原始数据更大（如 Elasticsearch 推荐内存 >= 64GB）。
3. 3.**中文分词准确性**
   需专业分词器（如 IK Analyzer）解决歧义问题。



### 4、悲观锁和乐观锁的怎么实现

**1 悲观锁 (Pessimistic Locking)**

**核心思想**：**"先加锁，再操作"**。默认认为并发冲突会发生，因此在访问数据前先加锁，确保操作期间数据不被修改。

**实现方式**

1. 数据库行级锁 (MySQL示例)

```
-- 开始事务
START TRANSACTION;

-- 加悲观锁 (SELECT ... FOR UPDATE)
SELECT * FROM accounts WHERE id = 1 FOR UPDATE;

-- 执行业务操作
UPDATE accounts SET balance = balance - 100 WHERE id = 1;

-- 提交事务（释放锁）
COMMIT;
```

**关键点**：

- •`FOR UPDATE` 会对查询结果加**排他锁(X锁)**
- •其他事务尝试加锁时会被阻塞，直到当前事务提交
- •适用于**高冲突场景**（如库存扣减）

2.java中的synchronized



**2 乐观锁 (Optimistic Locking)**

**核心思想**：**"先操作，再检查"**。默认认为冲突很少发生，操作时不加锁，提交时检查数据是否被修改。

**实现方式**

1. 版本号机制 (数据库实现)

```sql
-- 表结构添加版本号字段
CREATE TABLE products (
    id INT PRIMARY KEY,
    name VARCHAR(50),
    stock INT NOT NULL,
    version INT DEFAULT 0  -- 乐观锁版本号
);

-- 更新时检查版本号
UPDATE products 
SET stock = stock - 1, 
    version = version + 1 
WHERE id = 1 
  AND version = 5;  -- 提交时携带原始版本号

-- 检查影响行数
if (affected_rows == 0) {
    // 版本号不匹配，重试或报错
}
```

**关键点**：

- •更新时检查版本号是否变化
- •冲突时返回影响行数0
- •需应用层处理重试逻辑

2.java中Atomic（CAS操作）



### 5、聚簇索引与非聚簇索引区别 

都是B+树的数据结构

- 聚簇索引:将数据存储与索引放到了一块、并且是按照一定的顺序组织的，找到索引也就找到了数据，数据的物理存放顺序与索引顺序是一致的，即:只要索引是相邻的，那么对应的数据一定也是相邻地存放在磁盘上的
- 非聚簇索引叶子节点不存储数据、存储的是数据行地址，也就是说根据索引查找到数据行的位置再取磁盘查找数据，这个就有点类似一本书的目录，比如我们要找第三章第一节，那我们先在这个目录里面找，找到对应的页码后再去对应的页码看文章。


优势:

1、查询通过聚簇索引可以直接获取数据，相比非聚簇索引需要第二次查询效率要高

2、聚簇索引对于范围查询的效率很高，因为其数据是按照大小排列的

3、聚簇索引适合用在排序的场合，非聚簇索引不适合

劣势;

1、维护索引很昂贵，特别是插入新行或者主键被更新导至要分页(pagesplit)的时候。建议在大量插入新行后，选在负载较低的时间段。

2、表因为使用uuId(随机ID)作为主键，使数据存储稀疏，这就会出现聚簇索引有可能有比全表扫面更慢，所以建议使用int的 自增主键



### 6、什么情况下mysql会索引失效

**1. 违反最左前缀原则（联合索引）**

**场景**：联合索引 `(a, b, c)`，但查询条件没有使用最左边的列

```sql
-- 有效：使用索引
SELECT * FROM table WHERE a = 1;
SELECT * FROM table WHERE a = 1 AND b = 2;
SELECT * FROM table WHERE a = 1 AND b = 2 AND c = 3;

-- 失效：没有使用最左列
SELECT * FROM table WHERE b = 2;
SELECT * FROM table WHERE c = 3;
SELECT * FROM table WHERE b = 2 AND c = 3;
```

**解决方案**：

- 调整查询条件顺序
- 创建合适的联合索引
- 为常用查询字段单独创建索引

**2. 对索引列进行运算或函数操作**

**场景**：在索引列上使用函数、计算或表达式

```sql
-- 失效：使用函数
SELECT * FROM table WHERE YEAR(create_time) = 2023;
SELECT * FROM table WHERE UPPER(name) = 'JOHN';

-- 失效：进行计算
SELECT * FROM table WHERE price + 10 > 100;
SELECT * FROM table WHERE id % 2 = 0;
```

**解决方案**：

```sql
-- 优化为：避免在索引列上操作
SELECT * FROM table WHERE create_time >= '2023-01-01' AND create_time < '2024-01-01';
SELECT * FROM table WHERE name = 'john'; -- 确保数据存储格式一致
```

**3. 使用 LIKE 模糊查询以通配符开头**

**场景**：`LIKE`查询以 `%`开头

```sql
-- 失效：以通配符开头
SELECT * FROM table WHERE name LIKE '%john%';
SELECT * FROM table WHERE name LIKE '%john';

-- 有效：以确定值开头
SELECT * FROM table WHERE name LIKE 'john%';
```

**解决方案**：

- 使用全文索引（FULLTEXT）替代 LIKE
- 使用搜索引擎（Elasticsearch）处理复杂搜索
- 调整业务逻辑，避免前置通配符

**4. 数据类型隐式转换**

**场景**：查询条件与索引列数据类型不匹配

```sql
-- 失效：字符串列使用数字查询（假设phone是varchar类型）
SELECT * FROM users WHERE phone = 13800138000;

-- 有效：类型匹配
SELECT * FROM users WHERE phone = '13800138000';
```

**解决方案**：

- 确保查询条件与列数据类型一致
- 使用显式类型转换（谨慎使用）

**5. OR 条件使用不当**

**场景**：OR 条件中包含非索引列

```sql
-- 失效：其中一个条件无索引
SELECT * FROM table WHERE indexed_column = 1 OR non_indexed_column = 2;

-- 解决方案：分别查询后合并
(SELECT * FROM table WHERE indexed_column = 1)
UNION
(SELECT * FROM table WHERE non_indexed_column = 2);
```

**6. 索引列使用 NOT、!=、<> 操作符**

**场景**：使用否定条件

```sql
-- 可能失效
SELECT * FROM table WHERE status != 'active';
SELECT * FROM table WHERE id <> 100;

-- 优化方案
SELECT * FROM table WHERE status IN ('inactive', 'pending', 'deleted');
SELECT * FROM table WHERE id < 100 OR id > 100;
```

**7. 范围查询后的条件无法使用索引**

**场景**：联合索引中，范围查询后的列无法使用索引

```sql
-- 联合索引 (a, b, c)
SELECT * FROM table WHERE a = 1 AND b > 10 AND c = 3;
-- 只有a和b使用索引，c不能使用索引
```

**解决方案**：

- 调整索引顺序：将等值查询列放在前面
- 使用覆盖索引

**8. 表数据量小**

**场景**：当表数据量很小时，MySQL 可能选择全表扫描

```sql
-- 小表可能不使用索引
SELECT * FROM small_table WHERE indexed_column = 'value';
```

**解决方案**：无需优化，全表扫描可能更高效



### 7、B+tree 与 B-tree区别

B-tree

![](E:/MK/SpringFamily/Interview/md/images/d_07_1.png)

B+tree

![](E:/MK/SpringFamily/Interview/md/images/d_07_2.png)

**1 数据存储方式**

- **B树**：
  - 所有节点（包括内部节点）都存储数据
  - 每个键值对都包含完整的数据或数据指针
  - 查询可能在内部节点终止
- **B+树**：
  - **仅叶子节点存储实际数据**
  - 内部节点只存储键值和子节点指针（导航作用）
  - 所有查询必须到达叶子节点

**2 节点连接方式**

- **B树**：
  - 节点间无直接连接
  - 范围查询需要中序遍历整棵树
- **B+树**：
  - **叶子节点通过双向指针连接**
  - 形成有序链表结构
  - 范围查询只需遍历叶子链表

**3 空间利用率**

- **B树**：

  ```java
  // B树节点结构
  class BTreeNode {
      Key[] keys;          // 键值
      Data[] data;         // 数据
      BTreeNode[] children;// 子节点指针
  }
  ```

•每个节点都需要存储数据指针

•空间利用率较低

•**B+树**

```java
// B+树内部节点
class BPlusInternalNode {
    Key[] keys;          // 键值
    BPlusNode[] children;// 子节点指针
}

// B+树叶节点
class BPlusLeafNode {
    Key[] keys;          // 键值
    Data[] data;         // 数据
    BPlusLeafNode next;  // 下一个叶节点
    BPlusLeafNode prev;  // 上一个叶节点
}
```

•内部节点不存储数据，可容纳更多键值

•相同页大小下存储更多导航信息

**4 查询性能对比**

**点查询：**

```
SELECT * FROM table WHERE id = 100;
```

- B树：可能在内部节点找到结果
- B+树：必须到达叶子节点
- **性能相当**（B+树树高通常更低）

**范围查询：**

```sql
SELECT * FROM table WHERE id BETWEEN 100 AND 200;
```

- B树：

  定位起始键

  中序遍历整棵树

  随机磁盘访问

- B+树：

  定位起始叶子节点

  沿链表顺序扫描

  顺序磁盘访问

- **B+树性能优势明显**（5-10倍提升）

**7.1 为什么数据库选择B+树？**

1. 磁盘I/O优化

- B+树内部节点可存储更多键值
- 树高更低 → 减少磁盘访问次数
- 顺序访问 → 预读优化

2. 范围查询优势

- B+树：定位起始叶子节点后顺序扫描
- B树：多次随机访问

**7.2 B+树树高更低的含义与影响**

​		**树高**指的是从根节点到最远叶子节点所经过的层级数。在树结构中，树高直接决定了查找操作需要访问的节点数量。

​		**树高 = 3**（根节点→内部节点→叶子节点）

​		B+tree内部节点只存指针不存数据内容，每一页（每一节点）存的指针更多。

​		**扇出**：每个节点能够包含的子节点数量

**计算示例**（16KB页，8字节键，6字节指针）：

- **B树扇出**：16384 / (8 + 6 + 6) ≈ 819
  - 键值(8) + 数据指针(6) + 子节点指针(6)
- **B+树扇出**：16384 / (8 + 6) ≈ 1170
  - 只存储键值(8) + 子节点指针(6)

**B+树扇出比B树高约43%**，意味着：

- 每个内部节点能存储更多键值
- 相同数据量需要的层级更少
- 树高自然更低

**7.3 树低更低的实际意义**

1. **性能提升**：减少磁盘I/O次数，直接提升查询速度
2. **效率优化**：范围查询和全表扫描效率显著提高
3. **资源节约**：减少内存缓存压力（缓存更少节点）
4. **并发改善**：降低锁竞争，提高系统吞吐量
5. **可扩展性**：支持更大规模的数据集

**最终结论**：B+树通过**更高的扇出**实现**更矮的树高**，从而在大多数数据库场景中提供**更优的性能表现**，这正是为什么现代数据库系统普遍选择B+树作为索引结构的主要原因。



### 8、以MySQL为例Linux下如何排查问题 

1 查看服务状态

```bash
# 检查MySQL服务状态
systemctl status mysql
# 或
service mysql status

# 查看是否正在运行
ps aux | grep mysqld
netstat -tulpn | grep 3306
```

2 查看错误日志

如：排除主从问题

```bash
# IO线程连接主库失败
[ERROR] Slave I/O for channel '': error connecting to master 'user@master:3306' - retry-time: 60 retries: 1

# SQL线程应用日志失败
[ERROR] Slave SQL for channel '': Could not execute Write_rows event on table test.t1; 
Error 'Duplicate entry '1' for key 'PRIMARY'' on query, Error_code: 1062

# 中继日志问题
[ERROR] Error in Log_event::read_log_event(): 'Event too small', data_len: 0, event_type: 0
```

3 慢查询分析

​		由于慢查询日志记录默认是关闭的,所以开启数据库mysql的慢查询记录 的功能 从慢查询日志中去获取哪些sql语句时慢查询  默认10S ,从中获取到sql语句进行分析

4 资源使用分析

​		查看mysql内存使用。

5 网络问题排查

​		检查端口监听，测试网络连通性，检查DNS解析问题



**8.1 监控告警设置**

- 设置连接数超过80%告警
- 设置慢查询数量突增告警
- 设置磁盘空间不足告警
- 设置复制延迟告警（如果使用复制）

**8.2 Explain分析一条慢sql**

**Id**：执行顺序 如果单表的话,无参考价值 如果是关联查询,会据此判断主表 从表

Select_type ：simple

**Table**：表

**Type**： ALL（全表扫描）、index（索引扫描）、range（范围扫描）、ref（索引查找）

Possible_keys

**Key** ：MYSQL使用的索引

Key_len  ： 索引字段数据结构所使用长度 与是否有默认值null 以及对应字段到数据类型有关，有一个理论值 有一个实际使用值也即key_len的值

**Rows**  ：显示MYSQL执行查询的行数，简单且重要，数值越大越不好，说明没有用好索引

**Extra**  ：常见的值：usingfilesort 使用磁盘排序算法进行排序，事关排序 分组 的字段是否使用索引的核心参考值。Using index（覆盖索引）、Using temporary（临时表）、Using filesort（文件排序）

**8.3 Extra解读**

​		EXPLAIN 的 Extra 列是查询执行计划中最关键的信息之一，它揭示了 MySQL 如何执行查询的细节

1. 性能优化提示（绿色信号）

| **Extra 值**                          | **含义**           | **优化建议**       | **示例场景**                                       |
| ------------------------------------- | ------------------ | ------------------ | -------------------------------------------------- |
| **Using index**                       | 使用覆盖索引       | 尽可能使用覆盖索引 | `SELECT id FROM users WHERE age > 30`              |
| **Using index condition**             | 使用索引条件过滤   | 确保索引有效       | `SELECT * FROM orders WHERE product_id IN (1,2,3)` |
| **Using where with pushed condition** | 条件下推到存储引擎 | 验证条件下推效果   | NDB集群表查询                                      |

2. 执行策略说明（黄色信号）

| **Extra 值**          | **含义**         | **潜在问题**    | **优化建议**          |
| --------------------- | ---------------- | --------------- | --------------------- |
| **Using where**       | 服务器层过滤数据 | 可能扫描过多行  | 添加合适索引          |
| **Using temporary**   | 使用临时表       | 内存/磁盘开销大 | 优化GROUP BY/ORDER BY |
| **Using filesort**    | 文件排序         | 高CPU/IO消耗    | 添加排序字段索引      |
| **Using join buffer** | 使用连接缓冲区   | 表连接效率低    | 优化JOIN条件或索引    |

3. 潜在问题警告（红色信号）

| **Extra 值**                     | **含义**           | **严重程度** | **解决方案** |
| -------------------------------- | ------------------ | ------------ | ------------ |
| **Using MRR**                    | 多范围读取         | 通常有益     | 保持默认启用 |
| **Using index for group-by**     | 索引优化GROUP BY   | 良好信号     | 保持当前索引 |
| **Impossible WHERE**             | WHERE条件永不成立  | 查询无意义   | 检查业务逻辑 |
| **Select tables optimized away** | 优化器优化掉表访问 | 良好信号     | 无需优化     |

**8.4 条件下推**

​		条件下推（Condition Pushdown）是 MySQL 优化器的核心功能，它能将 WHERE 条件**提前到存储引擎层执行**，大幅减少不必要的数据访问。

**优化效果**：

- 减少磁盘I/O
- 降低内存占用
- 提升查询速度2-10倍

举例：

```sql
-- 条件下推验证
EXPLAIN SELECT * FROM orders 
WHERE status = 'completed' AND amount > 1000;
-- 说明​​：status = 'completed'被下推到存储引擎层执行

```




### 9、如何处理慢查询

​		在业务系统中，除了使用主键进行的查询，其他的都会在测试库上测试其耗时，慢查询的统计主要由运维在做，会定期将业务中的慢查询反馈给我们。

​		慢查询的优化首先要搞明白慢的原因是什么?是查询条件没有命中索引?是加载了不需要的数据列?还是数据量太大?

​		所以优化也是针对这三个方向来的

​		首先分析语句，看看是否加载了额外的数据，可能是查询了多余的行并且抛弃掉了，可能是加载了许多结果中并不需要的列，对语句进行分析以及重写。

​		分析语句的执行计划，然后获得其使用索引的情况，之后修改语句或者修改索引，使得语句可以尽可能的命中索引。

​		如果对语句的优化已经无法进行，可以考虑表中的数据量是否太大，如果是的话可以进行横向或者纵向的分表。
​		也可将mysql迁移至starrocks。

**9.1 StarRocks**

​		**StarRocks** 是一款高性能、全场景的**开源分布式分析型数据库**（MPP -- Massively Parallel Processing，大规模并行处理）。

设计目标：

1. **极速分析**：在海量数据（PB级别）上，实现亚秒级（Sub-second）的查询响应。
2. **高并发**：支持数百甚至上千用户同时进行复杂的数据分析查询，而不会显著降低性能。
3. **实时分析**：支持对实时更新的数据立即进行查询分析，无需等待传统的 T+1 数据仓库延迟。
4. **全面支持标准SQL**：降低了用户的学习和使用成本，可以直接用熟悉的工具（如BI工具）连接它。

**9.2 starrocks与mysql对比**

​		StarRocks 和 MySQL 虽然都支持 SQL，但它们的**设计目标、架构和适用场景完全不同**。

•**MySQL是你的“业务系统”，负责“写”和“事务”。**

•**StarRocks是你的“数据分析系统”，负责“读”和“分析”。**

**9.3 业务场景**

选择 **MySQL** 当你的业务是：

- **核心交易系统**：如订单、支付、用户账户管理。
- **高频率的随机读写**：每秒需要处理大量INSERT、UPDATE、DELETE和按主键查询的操作。
- **强事务一致性要求**：需要严格的ACID事务保证，如银行转账。
- **数据量在TB级以下**，且复杂分析查询较少。

选择 **StarRocks** 当你的业务是：

- •**数据分析和商业智能（BI）**：如实时报表、仪表盘、即席查询（Ad-hoc）。
- **用户行为分析**：如漏斗分析、留存分析、多维钻取。
- **日志/事件分析**：分析大量的应用程序日志或事件数据。
- **构建实时数据仓库**：需要对企业内部的海量数据进行快速、并行的分析。
- **需要执行多表关联、大规模聚合计算**的复杂查询。

**9.4 协同工作的范式**

​		在现代数据架构中，MySQL和StarRocks**不是取代关系，而是协作关系**，这是一种非常常见的模式：

1. **数据产生于MySQL**：业务系统使用MySQL处理高并发事务。
2. **数据同步到StarRocks**：通过CDC（Change Data Capture）工具（如Canal、Debezium）将MySQL的数据**实时同步**到StarRocks。
3. **在StarRocks中进行分析**：所有的报表、分析和复杂查询都在StarRocks中执行，**完全不影响MySQL的生产业务**。

**9.5 starrocks四大模型**

| **模型**     | **核心功能**      | **优点**                           | **缺点**                     | **典型场景**                      |
| ------------ | ----------------- | ---------------------------------- | ---------------------------- | --------------------------------- |
| **明细模型** | 存储原始数据      | 灵活，支持任意查询                 | 存储成本高，查询性能依赖索引 | 日志、事件流水、即席查询          |
| **聚合模型** | 预聚合数据        | **查询性能极快**                   | 失去明细，只能按固定维度查询 | 固定报表、BI分析看板              |
| **更新模型** | 按Key更新数据     | 支持行级更新                       | 更新性能相对主键模型较低     | 用户/商品档案表（更新不极端频繁） |
| **主键模型** | 高效Upsert/Delete | **更新删除性能最佳**，支持部分更新 | 语法略有不同，需更高版本     | 实时CDC同步、极频繁更新的业务表   |



### 10、数据库分表操作

**1 核心思路：先规划，后实施**

​		分表的本质是将一个逻辑上的大表，在物理上拆分成多个小表（Table Sharding）。对应用程序来说，它可能仍然是一个整体，但数据库实际存储和管理的是多个文件。

**核心目标**：

- **性能提升**：减少单表数据量，降低 B+Tree 深度，加速查询。
- **分散 I/O**：将数据分布到不同磁盘，提升并发读写能力。
- **便于管理**：例如，可以快速删除某个时间段的过期数据（按时间分表）。

**2 分表策略选择（关键决策）**

根据拆分维度不同，主要分为两种策略：

2-1 垂直分表 (Vertical Sharding)

- **思路**：按列拆分，“大表拆小表”。将不常用、长度较大的字段（如 `TEXT`, `BLOB`, `VARCHAR(1000)`）拆分到一张“扩展表”中，与原表的主键形成 1:1 关系。
- **适用场景**：表字段非常多，且存在“热点字段”和“冷门字段”之分。
- **优点**：减少磁盘 I/O，让热点数据页能缓存更多数据行。
- **缺点**：未解决单表数据行过多的根本问题。应用层需要 JOIN 查询才能获取完整数据。

**示例**：

原表 `user`(`user_id`, `username`, `password`, `age`, `address`, `description`, `avatar`)。

拆分为：

- `user_base`(`user_id`, `username`, `password`, `age`) -- 高频查询
- `user_ext`(`user_id`, `address`, `description`, `avatar`) -- 低频查询

2-2 水平分表 (Horizontal Sharding)

- **思路**：按行拆分，“大数据分小块”。将表的数据行按照某种规则（如取模、范围、哈希等）分布到多个**结构完全相同**的表中。
- **适用场景**：单表数据行数巨大（千万/亿级），是解决大数据量的核心方案。
- **优点**：从根本上解决单表数据量过大的问题。
- **缺点**：逻辑复杂，应用层需要根据规则路由到具体表。

**常用路由规则**：

| 规则              | 描述               | 优点           | 缺点               | 示例                                |
| ----------------- | ------------------ | -------------- | ------------------ | ----------------------------------- |
| **范围分表**      | 按ID或时间范围划分 | 易于管理和扩容 | 容易产生数据热点   | `user_202301`, `user_202302`        |
| **哈希分表**      | 对分表键取模       | 数据分布均匀   | 扩容复杂（Rehash） | `user_id % 4`-> `user_0`到 `user_3` |
| **地理/业务分表** | 按业务属性划分     | 符合业务特性   | 可能分布不均       | `user_bj`, `user_sh`, `user_sz`     |



### 11、MySQL优化 

1. 为频繁查询的WHERE条件字段添加索引
2. 为JOIN关联字段添加索引
3. 为ORDER BY/GROUP BY字段添加索引
4. 避免SELECT *
5. 避免不必要的子查询，尽量缩小子查询的结果
6. 避免在索引列上使用计算、not in 和<>等操作
7. 当只需要一行数据的时候使用limit 1
8. 保证单表数据不超过200W，适时分割表。针对查询较慢的语句，可以使用explain 来分析该语句具体的执行情况。
9. 考虑读写分离
10. 避免改变索引列的类型。

**11.1 改变索引字段的类型，索引还会生效吗？**

​		改变索引字段的数据类型**可能导致索引失效**，具体是否生效取决于**变更类型、存储引擎和变更方式**。以下是详细分析：

1. **隐式类型转换（查询时）**

```sql
-- 示例：phone是VARCHAR但用数字查询
SELECT * FROM users WHERE phone = 13800138000;
```

- **结果**：索引**失效**，全表扫描

- **原因**：MySQL需将phone列转为数字再比较

- **解决方案**：

- ```sql
  SELECT * FROM users WHERE phone = '13800138000'; -- 保持类型一致
  ```

2. **显式修改列数据类型**

场景1：兼容类型变更

```sql
ALTER TABLE users MODIFY age SMALLINT; -- 原为TINYINT
```

- **结果**：索引**保持生效**
- **允许的变更**：
  - `INT`→ `BIGINT`
  - `VARCHAR(10)`→ `VARCHAR(20)`
  - `DATETIME`→ `TIMESTAMP`（需注意范围）

场景2：不兼容类型变更

```sql
ALTER TABLE users MODIFY email TEXT; -- 原为VARCHAR(255)
```

- **结果**：索引**立即失效**
- **高风险变更**：
  - 字符串 ↔ 数值类型
  - `VARCHAR`↔ `TEXT/BLOB`
  - 时间格式互转（如 `DATE`→ `INT`）



### 12、SQL语句优化案例

**例1**：where 子句中可以对字段进行 null 值判断吗？

​		可以，比如 `select id from t where num is null` 这样的 sql 也是可以的。但是最好不要给数据库留NULL，尽可能的使用 NOT NULL 填充数据库。不要以为 NULL 不需要空间，比如：char(100) 型，在字段建立时，空间就固定了， 不管是否插入值（NULL 也包含在内），都是占用 100 个字符的空间的，如果是 varchar 这样的变长字段，null 不占用空间。可以在 num 上设置默认值 0，确保表中 num 列没有 null 值，然后这样查询：select id from t where num= 0。

**例2**：如何优化?下面的语句？

```sql
select * 
from admin left join log 
on admin.admin_id = log.admin_id 
where log.admin_id>10
```

优化为：

```sql
select * 
from (select * from admin where admin_id>10) T1 left join log 
on T1.admin_id = log.admin_id
```

使用 JOIN 时候，应该用小的结果驱动大的结果（left join 左边表结果尽量小如果有条件应该放到左边先处理， right join 同理反向），同时尽量把牵涉到多表联合的查询拆分多个 query（多个连表查询效率低，容易到之后锁表和阻塞）。

**例3**：limit 的基数比较大时使用 between

例如：

```sql
select * from admin order by admin_id limit 100000,10
```

优化为：

```sql
select * from admin where admin_id between 100000 and 100010 order by admin_id
```

**例4**：尽量避免在列上做运算，这样导致索引失效

例如：

```sql
select * from admin where year(admin_time)>2014
```

优化为：

```sql
select * from admin where admin_time> '2014-01-01′
```



### 13、有哪些数据库设计规范

**（一）基础规范**

1、表存储引擎必须使用InnoD，表字符集默认使用utf8，必要时候使用utf8mb4

> 解读：
>
> （1）通用，无乱码风险，汉字3字节，英文1字节
>
> （2）utf8mb4是utf8的超集，有存储4字节例如表情符号时，使用它

2、禁止使用存储过程，视图，触发器，Event

> 解读：
>
> （1）对数据库性能影响较大，互联网业务，能让站点层和服务层干的事情，不要交到数据库层
>
> （2）调试，排错，迁移都比较困难，扩展性较差

3、禁止在数据库中存储大文件，例如照片，可以将大文件存储在对象存储系统，数据库中存储路径

4、禁止在线上环境做数据库压力测试

5、测试，开发，线上数据库环境必须隔离

**（二）命名规范**

1、库名，表名，列名必须用小写，采用下划线分隔

> 解读：abc，Abc，ABC都是给自己埋坑

2、库名，表名，列名必须见名知义，长度不要超过32字符

> 解读：tmp，wushan谁知道这些库是干嘛的

3、库备份必须以bak为前缀，以日期为后缀

4、从库必须以-s为后缀

5、备库必须以-ss为后缀

**（三）表设计规范**

1、单实例表个数必须控制在2000个以内

2、单表分表个数必须控制在1024个以内

3、表必须有主键，推荐使用UNSIGNED整数为主键

> 潜在坑：删除无主键的表，如果是row模式的主从架构，从库会挂住

4、禁止使用外键，如果要保证完整性，应由应用程式实现

> 解读：外键使得表之间相互耦合，影响update/delete等SQL性能，有可能造成死锁，高并发情况下容易成为数据库瓶颈

5、建议将大字段，访问频度低的字段拆分到单独的表中存储，分离冷热数据

**（四）列设计规范**

1、根据业务区分使用tinyint/int/bigint，分别会占用1/4/8字节

2、根据业务区分使用char/varchar

> 解读：
>
> （1）字段长度固定，或者长度近似的业务场景，适合使用char，能够减少碎片，查询性能高
>
> （2）字段长度相差较大，或者更新较少的业务场景，适合使用varchar，能够减少空间

3、根据业务区分使用datetime/timestamp

> 解读：前者占用5个字节，后者占用4个字节，存储年使用YEAR，存储日期使用DATE，存储时间使用datetime

4、必须把字段定义为NOT NULL并设默认值

> 解读：
>
> （1）NULL的列使用索引，索引统计，值都更加复杂，MySQL更难优化
>
> （2）NULL需要更多的存储空间
>
> （3）NULL只能采用IS NULL或者IS NOT NULL，而在=/!=/in/not in时有大坑

5、使用INT UNSIGNED存储IPv4，不要用char(15)

6、使用varchar(20)存储手机号，不要使用整数

> 解读：
>
> （1）牵扯到国家代号，可能出现+/-/()等字符，例如+86
>
> （2）手机号不会用来做数学运算
>
> （3）varchar可以模糊查询，例如like ‘138%’

7、使用TINYINT来代替ENUM

> 解读：ENUM增加新值要进行DDL操作

**（五）索引规范**

1、唯一索引使用uniq_[字段名]来命名

2、非唯一索引使用idx_[字段名]来命名

3、单张表索引数量建议控制在5个以内

> 解读：
>
> （1）互联网高并发业务，太多索引会影响写性能
>
> （2）生成执行计划时，如果索引太多，会降低性能，并可能导致MySQL选择不到最优索引
>
> （3）异常复杂的查询需求，可以选择ES等更为适合的方式存储

4、组合索引字段数不建议超过5个

> 解读：如果5个字段还不能极大缩小row范围，八成是设计有问题

5、不建议在频繁更新的字段上建立索引

6、非必要不要进行JOIN查询，如果要进行JOIN查询，被JOIN的字段必须类型相同，并建立索引

> 解读：踩过因为JOIN字段类型不一致，而导致全表扫描的坑么？

7、理解组合索引最左前缀原则，避免重复建设索引，如果建立了(a,b,c)，相当于建立了(a), (a,b), (a,b,c)

**（六）SQL规范**

1、禁止使用select *，只获取必要字段

> 解读：
>
> （1）select *会增加cpu/io/内存/带宽的消耗
>
> （2）指定字段能有效利用索引覆盖
>
> （3）指定字段查询，在表结构变更时，能保证对应用程序无影响

2、insert必须指定字段，禁止使用insert into T values()

> 解读：指定字段插入，在表结构变更时，能保证对应用程序无影响

3、隐式类型转换会使索引失效，导致全表扫描

4、禁止在where条件列使用函数或者表达式

> 解读：导致不能命中索引，全表扫描

5、禁止负向查询以及%开头的模糊查询

> 解读：导致不能命中索引，全表扫描

6、禁止大表JOIN和子查询

7、同一个字段上的OR必须改写问IN，IN的值必须少于50个

8、应用程序必须捕获SQL异常

> 解读：方便定位线上问题



### 14、如何设计数据库

**表设计步骤：**

步骤一：需求分析 -> 识别实体与属性

​		**目标**：将业务需求转化为实体（Entity）和属性（Attribute）。

​		**方法**：与产品经理、开发团队沟通，分析业务文档和用户故事。

步骤二：定义主键 -> 确立唯一标识

​		为每个实体（表）选择一个**主键（Primary Key）**。

- **代理主键（Surrogate Key）**：一个与业务无关的、自增的数字ID（如 `BIGINT AUTO_INCREMENT`）。**性能好，强烈推荐**。

步骤三：建立关系 -> 定义外键

​		分析实体间的关系（1:1, 1:N, M:N），并**使用外键（Foreign Key）** 在数据库中建立联系。

步骤四：规范化 -> 减少数据冗余

​		**规范化（Normalization）** 是组织数据以减少冗余的过程。通常至少需要满足第三范式（3NF）。

步骤五：反范式化 -> 提升查询性能

​		**反范式化（Denormalization）** 是基于性能考量，**故意增加冗余**，避免多表关联查询的策略。

步骤六：定义字段 -> 选择合适的数据类型

​		为每个属性选择最合适、最精确的数据类型。

步骤七：定义约束 -> 保证数据完整性

​		使用约束来强制保证数据的正确性和可靠性。

- `NOT NULL`：强制字段必须有值。
- `DEFAULT`：为字段设置默认值。
- `UNIQUE`：确保字段值唯一（如用户名、邮箱）。

**14.1 三范式**

​		三范式（3NF）是数据库设计的**黄金标准**，它能有效解决数据冗余、更新异常等问题

1. 第一范式（1NF）：**原子性**

**要求**：每列都是**不可再分**的最小数据单元

​		每一列属性(字段)不可分割的,字段必须保证原子性
​		两列的属性值相近或者一样的,尽量合并到一列或者分表,确保数据不冗余

2. 第二范式（2NF）：**完全依赖**

**要求**：在1NF基础上，**非主属性必须完全依赖主键**

​		每一行的数据只能与其中一行有关。即 主键  一行数据只能做一件事情或者表达一个意思,只要数据出现重复,就要进行表的拆分。

3. 第三范式（3NF）：**直接依赖**

**要求**：在2NF基础上，**消除传递依赖**

​		数据不能存在传递关系,每个属性都跟主键有直接关联而不是间接关联。

> 例：学号 -> 所在院校 -> 院校地址 。存在间接关联关系，明显不符合第三范式。我们应该做两张表：student表、school表



### 15、常见SQL

**例3：**

一个叫team的表，里面只有一个字段name,一共有4条纪录，分别是a,b,c,d,对应四个球队，现在四个球队进行比赛，用一条sql语句显示所有可能的比赛组合.

答：

```SQL
select a.name, b.name  
from team a, team b   
where a.name < b.name  
```

**例4：**

怎么把这样一个表
year           month amount
1991    1         1.1
1991   2         1.2
1991   3         1.3
1991   4         1.4
1992   1         2.1
1992   2         2.2
1992   3         2.3
1992   4         2.4
查成这样一个结果
year           m1       m2       m3       m4
1991   1.1            1.2            1.3            1.4
1992   2.1            2.2            2.3            2.4 
答：

```SQL
select year,   
(select amount from aaa m where month=1 and m.year=aaa.year) as m1,  
(select amount from aaa m where month=2 and m.year=aaa.year) as m2,  
(select amount from aaa m where month=3 and m.year=aaa.year) as m3,  
(select amount from  aaa m where month=4 and m.year=aaa.year) as m4  
from aaa group by year  
```



## 